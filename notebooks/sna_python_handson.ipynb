{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Analysis - Python Handson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:53:07.752829Z",
     "start_time": "2020-12-06T11:53:07.749953Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from networkx import nx\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import matrix_power\n",
    "\n",
    "### CUDA RAPIDS\n",
    "# import cugraph as cnx\n",
    "# import cudf\n",
    "# import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The data set is provided by Der Standard, one of the top Austrian newspapers.\n",
    "In the online Standard people can post comments below articles and up/down vote comments.\n",
    "The data set used in this handson and further in the project part of the course will consider a sample of those articles, comments, and votes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:53:09.966895Z",
     "start_time": "2020-12-06T11:53:07.757363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739094, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cols = [\"PostingCreatedAt\",\"ArticlePublishingDate\"]\n",
    "\n",
    "df1 = pd.read_csv('../data/Postings_01052019_15052019.csv',usecols=[\"ID_CommunityIdentity\", \"ID_Posting\", \"PostingCreatedAt\", \"ArticleTitle\",'ArticleChannel' ,\"ArticleRessortName\",\"ArticlePublishingDate\"],parse_dates=date_cols, sep=';')\n",
    "df2 = pd.read_csv('../data/Postings_16052019_31052019.csv', usecols=[\"ID_CommunityIdentity\", \"ID_Posting\",\"PostingCreatedAt\", \"ArticleTitle\",'ArticleChannel' ,\"ArticleRessortName\",\"ArticlePublishingDate\"], parse_dates=date_cols,sep=';')\n",
    "df=df1.append(df2, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:53:10.126443Z",
     "start_time": "2020-12-06T11:53:09.968211Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[(df.ArticleChannel == \"Inland\") & (~df.ArticleRessortName.isin([ \"Pensionen\", \"Eurofighter\",\"Off-Topic\"]))]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:53:10.130071Z",
     "start_time": "2020-12-06T11:53:10.127679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185509, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different entities in the data set: \n",
    "* Users - identified by *ID_CommunityIdentity* (or *UserCommunityName*)\n",
    "* Postings - identified by *ID_Posting*\n",
    "* Articles - identified by *ID_Article*\n",
    "\n",
    "Thus, there are different possibilities to build networks based on voting and posting data. \n",
    "We will concentrate now on the ***votes-to-network***. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:53:12.520973Z",
     "start_time": "2020-12-06T11:53:10.131280Z"
    }
   },
   "outputs": [],
   "source": [
    "date_cols = [\"VoteCreatedAt\",\"UserCreatedAt\"]\n",
    "votes1 = pd.read_csv('../data/Votes_01052019_15052019.csv',parse_dates=date_cols, sep=';')\n",
    "votes2 = pd.read_csv('../data/Votes_16052019_31052019.csv', parse_dates=date_cols,sep=';')\n",
    "votes=votes1.append(votes2, ignore_index=True)\n",
    "votes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:53:13.243948Z",
     "start_time": "2020-12-06T11:53:12.522497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1046528, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PostAndVotes=pd.merge(df,votes,on=\"ID_Posting\")\n",
    "PostAndVotes.head()\n",
    "PostAndVotes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:53:23.836234Z",
     "start_time": "2020-12-06T11:53:13.244956Z"
    }
   },
   "outputs": [],
   "source": [
    "PostAndVotes_less=PostAndVotes.groupby('ID_Posting').filter(lambda x : len(x)>5).copy()\n",
    "split_date= datetime.datetime(2019,5,17)\n",
    "\n",
    "PostAndVotes_before = PostAndVotes_less.loc[PostAndVotes_less['PostingCreatedAt'] <= split_date]\n",
    "PostAndVotes_after = PostAndVotes_less.loc[PostAndVotes_less['PostingCreatedAt'] > split_date]\n",
    "PostAndVotes_after.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:53:23.839897Z",
     "start_time": "2020-12-06T11:53:23.837305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before shape: (280769, 14)\n",
      "After shape: (579639, 14)\n"
     ]
    }
   ],
   "source": [
    "print('Before shape: ' + str(PostAndVotes_before.shape))\n",
    "print('After shape: ' + str(PostAndVotes_after.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line in the table above shows that a user (i.e., *ID_CommunityIdentiy*) posted a comment. Every post has its own uniqe identifier (i.e., *ID_Posting*). If a user votes for a posting then the vote is identified by the *ID_Posting* the voting was for, the *ID_CommunityIdentiy* from the voter. Next, it is also recorded, if the vote was negative or positive. This informtion is saved in  *VoteNegative* and *VotePositive* respectively.  \n",
    "\n",
    "We want to bring the structure above into following format: \n",
    "* source, i.e., the voting user\n",
    "* target, i.e., the post creator\n",
    "* weight, i.e., how often the source voted for the target (postive and negative)\n",
    "\n",
    "In other words, we are aiming for a *weighted edge-list*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T11:54:53.801418Z",
     "start_time": "2020-12-06T11:53:23.841445Z"
    }
   },
   "outputs": [],
   "source": [
    "edgeListBefore= PostAndVotes_before.groupby([\"ID_CommunityIdentity_x\",\"ID_CommunityIdentity_y\"]).agg({\"VoteNegative\": [(\"votes_neg_count\",\"sum\")], \"VotePositive\":[(\"votes_pos_count\",\"sum\")]})\n",
    "edgeListAfter= PostAndVotes_after.groupby([\"ID_CommunityIdentity_x\",\"ID_CommunityIdentity_y\"]).agg({\"VoteNegative\": [(\"votes_neg_count\",\"sum\")], \"VotePositive\":[(\"votes_pos_count\",\"sum\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:00:01.581542Z",
     "start_time": "2020-12-06T11:54:53.803549Z"
    }
   },
   "outputs": [],
   "source": [
    "edgeListBefore.columns=edgeListBefore.columns.droplevel()\n",
    "edgeListAfter.columns=edgeListAfter.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:00:01.584191Z",
     "start_time": "2020-12-06T11:53:07.787Z"
    }
   },
   "outputs": [],
   "source": [
    "edgeListBefore.loc[edgeListBefore[\"votes_neg_count\"]>10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:00:01.585584Z",
     "start_time": "2020-12-06T11:53:07.788Z"
    }
   },
   "source": [
    "### ATTENTION: \n",
    "PLEASE DEFINE YOUR WEIGHT BELOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:00:01.586613Z",
     "start_time": "2020-12-06T11:53:07.790Z"
    }
   },
   "outputs": [],
   "source": [
    "## original\n",
    "edgeListBefore[\"weight\"]=edgeListBefore[\"votes_pos_count\"]-edgeListBefore[\"votes_neg_count\"]\n",
    "edgeListAfter[\"weight\"]=edgeListAfter[\"votes_pos_count\"]-edgeListAfter[\"votes_neg_count\"]\n",
    "#edgeListBefore[\"weight\"]=np.where(edgeListBefore[\"votes_pos_count\"] >= edgeListBefore[\"votes_neg_count\"], 1, -1) \n",
    "#edgeListAfter[\"weight\"]=np.where(edgeListAfter[\"votes_pos_count\"] >= edgeListAfter[\"votes_neg_count\"], 1, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## v1\n",
    "# edgeListBefore[\"weight\"]= (1+edgeListBefore[\"votes_pos_count\"])/(1+edgeListBefore[\"votes_neg_count\"])\n",
    "# edgeListAfter[\"weight\"]=(1+edgeListAfter[\"votes_pos_count\"])/(1+edgeListAfter[\"votes_neg_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:00:01.587611Z",
     "start_time": "2020-12-06T11:53:07.795Z"
    }
   },
   "outputs": [],
   "source": [
    "edgeListBefore.rename_axis(['source', 'target'], inplace=True)\n",
    "edgeListAfter.rename_axis(['source', 'target'], inplace=True)\n",
    "edgeListAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forhist=edgeListAfter.groupby(level=0).size().hist(bins=200)\n",
    "#edgeListAfterT=edgeListAfter.groupby(level=0).filter(lambda x: 500 >x.size)\n",
    "#edgeListAfterT.groupby(level=0).size().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T12:00:01.588257Z",
     "start_time": "2020-12-06T11:53:07.798Z"
    }
   },
   "outputs": [],
   "source": [
    "edgesBefore = edgeListBefore.reset_index()\n",
    "edgesAfter = edgeListAfter.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesBefore.to_csv(\"../data/votes_to_comments_before.csv\", index=False)\n",
    "edgesAfter.to_csv(\"../data/votes_to_comments_after.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph\n",
    "\n",
    "We use the *networkx* library.\n",
    "Since we build a *votes-to-network* we have *source* nodes and *target* nodes. \n",
    "Thus, the network is directed.\n",
    "Therefore, we use *nx.Digraph()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# triangle_index - After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesBefore = pd.read_csv(\"../data/votes_to_comments_before.csv\")\n",
    "edgesAfter = pd.read_csv(\"../data/votes_to_comments_after.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(edgesAfter, \n",
    "                            source='source', \n",
    "                            target='target', \n",
    "                            edge_attr = 'weight',\n",
    "                            create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "UG = G.to_undirected()\n",
    "#count=0\n",
    "for node in G:\n",
    "    for ngbr in nx.neighbors(G, node):\n",
    "        if node in nx.neighbors(G, ngbr):\n",
    "            UG.edges[node, ngbr]['weight'] = (np.where( \n",
    "                G.edges[node, ngbr]['weight'] + G.edges[ngbr, node]['weight'] >=0,1,-1))\n",
    "           # if np.sign(G.edges[node, ngbr]['weight'])==np.sign(G.edges[ngbr, node]['weight']):\n",
    "                                       #       count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_matrix(UG)\n",
    "A3 = matrix_power(A,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108338617863109"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_absolut_3 = matrix_power(abs(A),3)\n",
    "triangle_index = (np.trace(A3) + np.trace(A_absolut_3)) / (2*np.trace(A_absolut_3))\n",
    "triangle_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edgesBefore = pd.read_csv(\"../data/votes_to_comments_before.csv\")\n",
    "G_2 = nx.from_pandas_edgelist(edgesBefore, \n",
    "                            source='source', \n",
    "                            target='target', \n",
    "                            edge_attr = 'weight',\n",
    "                            create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "UG_2 = G_2.to_undirected()\n",
    "for node in G_2:\n",
    "    for ngbr in nx.neighbors(G_2, node):\n",
    "        if node in nx.neighbors(G_2, ngbr):\n",
    "            UG_2.edges[node, ngbr]['weight'] = (np.where( \n",
    "                G_2.edges[node, ngbr]['weight'] + G_2.edges[ngbr, node]['weight'] >=0,1,-1))\n",
    "           # if np.sign(G.edges[node, ngbr]['weight'])==np.sign(G.edges[ngbr, node]['weight']):\n",
    "                                       #       count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_matrix(UG_2)\n",
    "A3 = matrix_power(A,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363584189943837"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_absolut_3 = matrix_power(abs(A),3)\n",
    "triangle_index_2 = (np.trace(A3) + np.trace(A_absolut_3)) / (2*np.trace(A_absolut_3))\n",
    "triangle_index_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## does not compute \n",
    "# fig = plt.figure(figsize=(50,50))\n",
    "# nx.draw_spring(G)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 19311\n",
      "Number of edges: 516939\n",
      "Average in degree:  26.7691\n",
      "Average out degree:  26.7691 Name: \n",
      "Type: Graph\n",
      "Number of nodes: 19311\n",
      "Number of edges: 509224\n",
      "Average degree:  52.7393\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G),nx.info(UG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509224"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = UG.edges()\n",
    "len(edges)\n",
    "# number of edges with weight 1\n",
    "#len(edgesBefore[edgesBefore.weight == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509224"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max weight of edges\n",
    "edges.weight.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average weight \n",
    "edges.weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network density and path lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network density\n",
    "nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average distance (i.e. average shortest path length)\n",
    "nx.average_shortest_path_length(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method average_shortest_path_length throws an exception if the underlying Graph is disconnected. Thus, one can calculate the average of all finite distances (i.e., existing shortest pathes) nx.single_source_shortest_path_length(G, N) delivers the length of all shortest pathes beginning from node N. Furthermore, the first shortest path is always the distance to itself (i.e., zero), which as to be filtered later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all distances\n",
    "distances = [list(nx.single_source_shortest_path_length(G,N).values()) for N in G.nodes]\n",
    "# Flatten the distances list! Currently list of lists of single node distances\n",
    "# and filter out the unnecessary zeroes\n",
    "distances = [distance for single_distances in distances for distance in single_distances if distance > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average\n",
    "np.mean(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To consider the weight one can use e.g. nx.single_source_dijkstra_path_length() But watch out, what does weight in our case mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diameter (i.e, longest shortest path)\n",
    "np.max(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G.subgraph(c) for c in nx.weakly_connected_components(G) delivers a Generator,which can be used to iterate over all weakly connected compontents (deliverd as a subgraph for further analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wccs = [c for c in (G.subgraph(c) for c in nx.weakly_connected_components(G))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of wccs\n",
    "len(wccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of wccs\n",
    "nx.number_weakly_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sizes of the wccs:\n",
    "\n",
    "nx.number_of_nodes() delivers the number of nodes of a graph. This can be done for all weakly connected components wcc in the weakly connected component list. Furthermore, with set() one can get the uniqe values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([nx.number_of_nodes(wcc) for wcc in wccs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not the uniqe values are in focus, but the for example how often a wcc with n Nodes appear, one can use Counter().most_common() as follwing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter([nx.number_of_nodes(wcc) for wcc in wccs]).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strongly connected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sccs = [c for c in (G.subgraph(c) for c in nx.strongly_connected_components(G))]\n",
    "Counter([nx.number_of_nodes(scc) for scc in sccs]).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local**\n",
    "\n",
    "nx.clustering(G) returns back a dictionary with clustering coefficients of each node.\n",
    "with the combination of sorted() and itemgetter() one can get a sorted list of (ID,clustering coeff.) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "sorted(nx.clustering(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"*the clustering coefficient quantifies how close the neighbours of i are to being a clique.*\" (lecture slides) i.e., how concentrated the neighbours of a nodes is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global**\n",
    "\n",
    "The global clustering coefficient can have alternative definitions:\n",
    "\n",
    "1) as the average of the local clustering coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that there might be differences if you use other tools (e.g., Gephi, Igraph, etc.).\n",
    "So, why does networkx delivers a different average clustering coefficiet?\n",
    "In order to find an answer, take a look at the nx.clustering() documentation (since nx.average_clustering is just averaging over the individual values). https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.cluster.clustering.html\n",
    "It says, that clustering coefficients for nodes with degrees lower than 2 is set to ZERO.\n",
    "\n",
    "Thus, there is no right or wrong way of implementation, but you have to be aware what you are using.\n",
    "\n",
    "2) as the ratio of triangles and connected triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.transitivity(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-Degree**\n",
    "\n",
    "[nx.in_degree_centrality(G)](https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.in_degree_centrality.html#networkx.algorithms.centrality.in_degree_centrality) delivers in-degree-centrality of each node in a graph G.\n",
    "Note, that the centralities are normalized.\n",
    "\n",
    "\n",
    "With a combination of sorted() and itemgetter() one can again get a sorted list of (Node, centrality) tuples.\n",
    "Where one can just take the first 5 for reporting.\n",
    "Note, reverse=True means in decreasing order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.in_degree_centrality(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User *588542* is replied the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out-Degree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.out_degree_centrality(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User *588542* also replies the most"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eigenvector-Centrality**\n",
    "\n",
    "Eigenvector centrality computes the centrality for a node based on the centrality of its neighbors. The eigenvector centrality for node i is the i-th element of the vector ð‘¥ defined by the equation\n",
    "\n",
    "ð´ð‘¥=ðœ†ð‘¥\n",
    "\n",
    "where ð´ is the adjacency matrix of the graph G with eigenvalue ðœ†. By virtue of the Perronâ€“Frobenius theorem, there is a unique solution ð‘¥, all of whose entries are positive, if ðœ† is the largest eigenvalue of the adjacency matrix ð´\n",
    "A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.eigenvector_centrality(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-closeness centrality**\n",
    "\n",
    "Closeness centrality of a node u is the reciprocal of the average shortest path distance to u over all n-1 reachable nodes.\n",
    "\n",
    "ð¶(ð‘¢)= (ð‘›âˆ’1)/âˆ‘ð‘‘(ð‘£,ð‘¢)\n",
    "\n",
    "where d(v, u) is the shortest-path distance between v and u, and n is the number of nodes that can reach u. Notice that the closeness distance function computes the incoming distance to u for directed graphs. To use outward distance, act on G.reverse()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.closeness_centrality(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out-closeness centrality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.closeness_centrality(G.reverse()).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Betweeness centrality**\n",
    "\n",
    "Betweenness centrality of a node ð‘£ is the sum of the fraction of all-pairs shortest paths that pass through ð‘£\n",
    "\n",
    "ð‘ðµ(ð‘£)=âˆ‘ðœŽ(ð‘ ,ð‘¡|ð‘£)/ðœŽ(ð‘ ,ð‘¡)\n",
    "\n",
    "where, ðœŽ(ð‘ ,ð‘¡) is the number of shortest (ð‘ ,ð‘¡)-paths, and ðœŽ(ð‘ ,ð‘¡|ð‘£) is the number of those paths passing through some node ð‘£ other than ð‘ ,ð‘¡ .\n",
    "\n",
    "\n",
    "Using k=100 nodes to estimate the betweeness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.betweenness_centrality(G, k=100).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hubs and Authorities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs_auth = nx.hits(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hub scores\n",
    "sorted(hubs_auth[0].items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authority scores\n",
    "sorted(hubs_auth[1].items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Page Rank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.pagerank(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triadic Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.algorithms.triads.triadic_census(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nxtriads import triads_by_type\n",
    "### Copied source code instead of updating to NetworkX == 2.5\n",
    "### see file nxtriads.py\n",
    "## __all__ = [\"triadic_census\", \"is_triad\", \"all_triplets\", \"all_triads\",\n",
    "## \"triads_by_type\", \"triad_type\", \"random_triad\", ]\n",
    "\n",
    "# convenience\n",
    "from networkx import nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 7378\n",
      "Number of edges: 85359\n",
      "Average in degree:  11.5694\n",
      "Average out degree:  11.5694\n"
     ]
    }
   ],
   "source": [
    "edges5d = pd.read_csv(\"../data/votes_to_comments_5days.csv\")\n",
    "G5 = nx.from_pandas_edgelist(edges5d, \n",
    "                            source='source', \n",
    "                            target='target', \n",
    "                            edge_attr = 'weight',\n",
    "                            create_using=nx.DiGraph())\n",
    "print(nx.info(G5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## kills kernel every time (pushes RAM >>10gb even on tiny graph)\n",
    "triads_5 = triads_by_type(G5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#triads_5.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
